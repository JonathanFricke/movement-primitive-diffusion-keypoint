# @package _global_
defaults:
  - dataset_config: dataset
  - workspace_config: dummy
  - override /hydra/launcher: submitit_slurm
  - _self_

# Set what should be used to determine if model performance increased in testing in environment
performance_metric: val_loss # can be anything that is returned in the dict of workspace.test_agent(agent)
performance_direction: min # {min, max}

device: auto  # {auto, cpu, cuda}. auto will select cuda if available, cpu otherwise

t_obs: 3
t_pred: 16  # Multiple of cotracker.step (8)
t_act: 16
predict_past: False

train_split: 0.9
dataset_fully_on_gpu: True

trajectory_dir: tomato_can_in_bowl_single_upright_from_sim

data_loader_config:
  shuffle: True
  pin_memory: False
  num_workers: 0
  batch_size: 256

 # Note: can be null, so training is only stopped by early_stopping
epochs: 1000 # unet lowdim: 5000, unet video: 1500, unet hybrid: 3000, unet real img: 600
early_stopping: False
# Note: we early stop based on success rate in env -> early stopping patience
# translates to eval_in_env_after_epochs * early_stopping_patience epochs.
early_stopping_warmup_epochs: 300
early_stopping_patience: 5
eval_in_env_after_epochs: 9999
num_trajectories_in_env: null # 24 distinct ways through the obstacle course -> multimodality
save_distance: 50 # additionally to the best model, save model every n epochs

group_from_overrides: False
name_from_overrides: True
ignore_in_name:
  - group
  - masterthesis

wandb:
  entity: ucioq-karlsruhe-institute-of-technology
  project: masterthesis_mpd_3dtracking
  group: transformer_diffusion
  mode: online # online, offline, disabled

# hydra:
#   mode: MULTIRUN  # needed for launcher to be used
#   sweeper:
#     params:
#       +seed: 2, 42, 821
#   launcher:
#     # launcher/cluster specific options
#     partition: "dev_gpu_4"
#     timeout_min: 60 # in minutes, maximum time on this queue
#     gres: gpu:1  # one gpu allocated
#     mem_per_gpu: 32000  # in MB
#     additional_parameters:
#       cpus-per-task: 4  # maybe more?
